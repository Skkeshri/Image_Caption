{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "A6-mPWUoOHKM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.models import load_model, Model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.image import load_img, img_to_array\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the VGG16 model for feature extraction\n",
        "base_model = VGG16(weights='imagenet')\n",
        "model_vgg16 = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)\n",
        "\n",
        "# Load the trained captioning model\n",
        "caption_model_path = '/content/caption_model.h5'\n",
        "caption_model = load_model(caption_model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLdXEiRCSKZf",
        "outputId": "c568e547-3719-40b3-9b13-41a3cf711508"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 25s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def generate_caption(model, tokenizer, image, max_length):\n",
        "    in_text = '<start>'\n",
        "    image = image.reshape((1, -1))  # Reshape the image features to fit the model's expected input shape\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length, padding='pre')\n",
        "        yhat = model.predict([image, sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = tokenizer.index_word.get(yhat, \"?\")\n",
        "        if word == '<end>':\n",
        "            break\n",
        "        in_text += ' ' + word\n",
        "\n",
        "    # Remove <start> and <end> tokens for the final output\n",
        "    final_caption = in_text.replace('<start> ', '').replace(' <end>', '')\n",
        "    return final_caption\n"
      ],
      "metadata": {
        "id": "A3INz8wRZqyC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    img = load_img(image_path, target_size=target_size)\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return preprocess_input(img_array)\n",
        "\n",
        "def extract_image_features(model, image_array):\n",
        "    features = model.predict(image_array)\n",
        "    return features[0]\n",
        "\n",
        "def caption_raw_image(image_path, tokenizer, max_length):\n",
        "    # Preprocess the image\n",
        "    image_array = preprocess_image(image_path)\n",
        "    # Extract features using VGG16\n",
        "    image_features = extract_image_features(model_vgg16, image_array)\n",
        "    # Generate the caption using the trained caption model\n",
        "    caption = generate_caption(caption_model, tokenizer, image_features, max_length)\n",
        "    return caption\n"
      ],
      "metadata": {
        "id": "KMfgAV0ASQwI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your tokenizer (assuming you've saved it as a pickle file in the original notebook)\n",
        "import pickle\n",
        "tokenizer_path = '/content/tokenizer.pkl'\n",
        "with open(tokenizer_path, 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "# Define your max_length (used during training)\n",
        "max_length = 38\n",
        "\n",
        "image_path = '/content/dog_standing.jpg'\n",
        "print(caption_raw_image(image_path, tokenizer, max_length))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp8tScLLSYVj",
        "outputId": "ee65fa2f-19a7-4061-c4b1-bd22f5c16318"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches approaches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/football.jpg'\n",
        "print(caption_raw_image(image_path, tokenizer, max_length))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54gVeT-kZILN",
        "outputId": "c915ee07-427d-4e2b-f872-63bd6208195e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed derssed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4bRdpQp1ahaK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}